[Training inputs]
# Location of the textfile containing tagged documents to learn from
TRAINFILE : /Users/luca/PycharmProjects/CRFNER/data/train.txt

# Comma separated entity names
ENTITIES : pnr,f_no,dep_apt,arr_apt,dep_date,dep_time,arr_date,arr_time

# Directory to store trained model in
MODEL_DIR : /Users/luca/PycharmProjects/CRFNER/models/conll_model_first_try

# Whether to tokenize character by character or word by word
# inside of HTML tags.
CHAR_BY_CHAR : False

# Lookout = amount of tokens to use for features
# Left lookout = amount of tokens to the left of the current token
LEFT_LOOKOUT : 7

# Right lookout = amount of tokens to the right of the current token
RIGHT_LOOKOUT : 7

[CRF]
### sklearn_crfsuite estimator parameters

# "For more information about these parameters, see the
# CRF class in sklearn_crfsuite/estimator.py"

# Max number of iterations.
ITERATIONS : 100
# CRF training algorithm.
ALGORITHM : lbfgs
# Cut-off threshold for occurrence frequency of a feature.
MIN_FREQ : 0
# Verbose training output - currently has to be set to False,
# because the sklearn-crfsuite module at the time of writing
# cannot do generators (for memory-saving) and verbose mode,
# see more here:
#   https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/4
VERBOSE : False

# Hyperparameter optimization using RandomizedSearchCV
# WARNING: Hyperparameter optimization does not work
# with generators... The training data and its features
# are loaded into memory and can get pretty big.
OPTIMIZE : True

# Number of parameter settings that are sampled. n_iter trades
# off runtime vs quality of the solution.
N_ITER : 10

# Number of jobs to run in parallel. Keep in mind every parallel
# job subprocess keeps the training data and features in its own
# memory.
N_JOBS : 5
