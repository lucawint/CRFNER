[Training inputs]
# Location of the textfile containing tagged documents to learn from.
TRAINFILE : /Users/luca/PycharmProjects/CRFNER/tests/test_files/conll/esp.train_inline.txt

# Comma separated entity names.
ENTITIES : LOC, PER, MISC, ORG

# Directory to store trained model in.
MODEL_DIR : /Users/luca/PycharmProjects/CRFNER/tests/test_files/conll/optimized 50/

# Whether to tokenize character by character or word by word
# inside of HTML tags.
CHAR_BY_CHAR : False

# Lookout = amount of tokens in vicinity to use for features.
# Left lookout = tokens to the left of the current token.
LEFT_LOOKOUT : 2

# Right lookout = tokens to the right of the current token.
RIGHT_LOOKOUT : 2

[CRF]
### sklearn_crfsuite estimator parameters

# "For more information about these parameters, see the
# CRF class in sklearn_crfsuite/estimator.py"

# Max number of iterations.
ITERATIONS : 100
# CRF training algorithm.
ALGORITHM : lbfgs
# Cut-off threshold for occurrence frequency of a feature.
MIN_FREQ : 0
# Verbose training output - currently has to be set to False,
# because the sklearn-crfsuite module at the time of writing
# cannot do generators (for memory-saving) and verbose mode,
# see more here:
#   https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/4
VERBOSE : False

# Hyperparameter optimization using RandomizedSearchCV
# WARNING: Hyperparameter optimization does not work
# with generators... The training data and its features
# are loaded into memory and can get pretty big.
OPTIMIZE : True

# Number of parameter settings that are sampled. n_iter trades
# off runtime vs quality of the solution.
N_ITER : 10

# Number of jobs to run in parallel. Keep in mind every parallel
# job subprocess keeps the training data and features in its own
# memory.
N_JOBS : 5
